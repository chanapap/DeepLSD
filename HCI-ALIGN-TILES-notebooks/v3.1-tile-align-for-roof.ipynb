{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap as lsc\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "from deeplsd.utils.tensor import batch_to_device\n",
    "from deeplsd.models.deeplsd_inference import DeepLSD\n",
    "# from deeplsd.geometry.viz_2d import plot_images, plot_lines\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(imgs, titles=None, cmaps='gray', dpi=300, size=3, pad=0):\n",
    "    \"\"\"Plot a set of images horizontally.\n",
    "    Args:\n",
    "        imgs: a list of NumPy or PyTorch images, RGB (H, W, 3) or mono (H, W).\n",
    "        titles: a list of strings, as titles for each image.\n",
    "        cmaps: colormaps for monochrome images.\n",
    "    \"\"\"\n",
    "    n = len(imgs)\n",
    "    if not isinstance(cmaps, (list, tuple)):\n",
    "        cmaps = [cmaps] * n\n",
    "    figsize = (size*n, size*3/4) if size is not None else None\n",
    "    fig, ax = plt.subplots(1, n, figsize=figsize, dpi=dpi)\n",
    "    if n == 1:\n",
    "        ax = [ax]\n",
    "    for i in range(n):\n",
    "        ax[i].imshow(imgs[i], cmap=plt.get_cmap(cmaps[i]))\n",
    "        ax[i].get_yaxis().set_ticks([])\n",
    "        ax[i].get_xaxis().set_ticks([])\n",
    "        ax[i].set_axis_off()\n",
    "        for spine in ax[i].spines.values():  # remove frame\n",
    "            spine.set_visible(False)\n",
    "        # if titles:\n",
    "            # ax[i].set_title(titles[i], fontsize=12)\n",
    "    fig.tight_layout(pad=pad)\n",
    "    fig.subplots_adjust(left=0, right=1, top=1, bottom=0, wspace=0, hspace=0)  # Remove spacing\n",
    "\n",
    "        \n",
    "        \n",
    "def plot_lines(lines, line_colors='orange', point_color='cyan',\n",
    "               ps=1, lw=0.5, indices=(0, 1), alpha=1):\n",
    "    \"\"\" Plot lines and endpoints for existing images.\n",
    "    Args:\n",
    "        lines: list of ndarrays of size (N, 2, 2).\n",
    "        line_colors: string, or list of list of tuples (one for per line).\n",
    "        point_color: unique color for all endpoints.\n",
    "        ps: size of the keypoints as float pixels.\n",
    "        lw: line width as float pixels.\n",
    "        indices: indices of the images to draw the matches on.\n",
    "        alpha: alpha transparency.\n",
    "    \"\"\"\n",
    "    if not isinstance(line_colors, list):\n",
    "        line_colors = [[line_colors] * len(l) for l in lines]\n",
    "    for i in range(len(lines)):\n",
    "        if ((not isinstance(line_colors[i], list))\n",
    "            and (not isinstance(line_colors[i], np.ndarray))):\n",
    "            line_colors[i] = [line_colors[i]] * len(lines[i])\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    # fig.set_size_inches(6, 4) \n",
    "    ax = fig.axes\n",
    "    assert len(ax) > max(indices)\n",
    "    axes = [ax[i] for i in indices]\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Plot the lines and junctions\n",
    "    for a, l, lc in zip(axes, lines, line_colors):\n",
    "        for i in range(len(l)):\n",
    "            # x1, x2 = (l[i, 0, 0], l[i, 1, 0])\n",
    "            # y1, y2 = (l[i, 0, 1], l[i, 1, 1])\n",
    "            line = matplotlib.lines.Line2D(\n",
    "                (l[i, 0, 0], l[i, 1, 0]), (l[i, 0, 1], l[i, 1, 1]),\n",
    "                zorder=1, c=lc[i], linewidth=lw, alpha=alpha)\n",
    "            a.add_line(line)\n",
    "        pts = l.reshape(-1, 2)\n",
    "        a.scatter(pts[:, 0], pts[:, 1], c=point_color, s=ps,\n",
    "                  linewidths=0, zorder=2, alpha=alpha)     \n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0, wspace=0, hspace=0)  # Remove spacing\n",
    "    plt.show()\n",
    "\n",
    "def shorten_lines(lines, shrink_factor=0.2):\n",
    "    \"\"\"\n",
    "    Shortens all lines by a given percentage from both ends.\n",
    "\n",
    "    Parameters:\n",
    "    - lines (Nx2x2 array): Array of lines in the format [[x1, y1], [x2, y2]]\n",
    "    - shrink_factor (float): Percentage to shorten from both ends (0.2 = 20%)\n",
    "\n",
    "    Returns:\n",
    "    - shortened_lines (Nx2x2 array): Array of shortened lines\n",
    "    \"\"\"\n",
    "    if shrink_factor < 0 or shrink_factor > 1:\n",
    "        raise ValueError(\"shrink_factor should be between 0 and 1\")\n",
    "\n",
    "    # Convert to float for precision\n",
    "    lines = np.array(lines, dtype=np.float32)\n",
    "\n",
    "    # Compute midpoints\n",
    "    midpoints = (lines[:, 0, :] + lines[:, 1, :]) / 2\n",
    "\n",
    "    # Move both endpoints closer to the midpoint\n",
    "    new_endpoints_1 = midpoints + (lines[:, 0, :] - midpoints) * (1 - shrink_factor)\n",
    "    new_endpoints_2 = midpoints + (lines[:, 1, :] - midpoints) * (1 - shrink_factor)\n",
    "\n",
    "    # Stack the new endpoints into (N,2,2) shape\n",
    "    shortened_lines = np.stack([new_endpoints_1, new_endpoints_2], axis=1)\n",
    "\n",
    "    return shortened_lines.astype(np.int32)  # Convert back to int\n",
    "\n",
    "\n",
    "def compute_slope(line, epsilon=1e-6):\n",
    "    \"\"\"Compute the slope of a line, handling vertical lines with epsilon.\"\"\"\n",
    "    (x1, y1), (x2, y2) = line\n",
    "    return (y2 - y1) / (x2 - x1 + epsilon)  # Avoid division by zero\n",
    "\n",
    "def compute_length(line):\n",
    "    \"\"\"Compute the Euclidean distance (length) of a line.\"\"\"\n",
    "    (x1, y1), (x2, y2) = line\n",
    "    return np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def check_lines_in_mask(mask_path, lines):\n",
    "    # Load binary mask image\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Ensure mask is binary (values 0 and 255)\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Convert mask to a boolean array (True for inside, False for outside)\n",
    "    mask_bool = mask > 0  # Pixels inside the mask are True\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width = mask.shape\n",
    "\n",
    "    inside_both = []\n",
    "    inside_one = []\n",
    "\n",
    "    for line in lines:\n",
    "        (x1, y1), (x2, y2) = line\n",
    "\n",
    "        # Clip coordinates to ensure they are within image bounds\n",
    "        x1 = np.clip(x1, 0, width - 1)\n",
    "        y1 = np.clip(y1, 0, height - 1)\n",
    "        x2 = np.clip(x2, 0, width - 1)\n",
    "        y2 = np.clip(y2, 0, height - 1)\n",
    "\n",
    "        # Check if both endpoints are inside the mask\n",
    "        is_inside_1 = mask_bool[int(y1), int(x1)]\n",
    "        is_inside_2 = mask_bool[int(y2), int(x2)]\n",
    "\n",
    "        if is_inside_1 and is_inside_2:\n",
    "            inside_both.append([[x1, y1], [x2, y2]])\n",
    "        elif is_inside_1 or is_inside_2:\n",
    "            inside_one.append([[x1, y1], [x2, y2]])\n",
    "\n",
    "    # Convert lists to NumPy arrays with shape (N,2,2) and (M,2,2)\n",
    "    inside_both = np.array(inside_both, dtype=np.int32) if inside_both else np.empty((0,2,2), dtype=np.int32)\n",
    "    inside_one = np.array(inside_one, dtype=np.int32) if inside_one else np.empty((0,2,2), dtype=np.int32)\n",
    "\n",
    "    return inside_both, inside_one\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def filter_short_lines(lines, image_height, min_ratio=0.01):\n",
    "    \"\"\"\n",
    "    Remove lines whose length is less than a percentage of the image height.\n",
    "\n",
    "    Args:\n",
    "        lines (np.ndarray): Array of shape (N, 2, 2) representing line segments.\n",
    "        image_height (int): Height of the image.\n",
    "        min_ratio (float): Minimum length as a fraction of image height (default 1%).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Filtered lines with valid lengths.\n",
    "    \"\"\"\n",
    "    if lines.size == 0:\n",
    "        return lines  # Return empty if no lines exist\n",
    "\n",
    "    min_length = min_ratio * image_height  # 1% of image height\n",
    "    lengths = np.linalg.norm(lines[:, 1, :] - lines[:, 0, :], axis=1)  # Compute lengths\n",
    "    filtered_lines = lines[lengths >= min_length]  # Keep only valid lines\n",
    "\n",
    "    return filtered_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "conf = {\n",
    "    'detect_lines': True,  # Whether to detect lines or only DF/AF\n",
    "    'line_detection_params': {\n",
    "        'merge': True,  # Whether to merge close-by lines\n",
    "        'filtering': True,  # Whether to filter out lines based on the DF/AF. Use 'strict' to get an even stricter filtering\n",
    "        'grad_thresh': 3,\n",
    "        'grad_nfa': True,  # If True, use the image gradient and the NFA score of LSD to further threshold lines. We recommand using it for easy images, but to turn it off for challenging images (e.g. night, foggy, blurry images)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load the model\n",
    "ckpt = '../weights/deeplsd_md.tar'\n",
    "ckpt = torch.load(str(ckpt), map_location='cpu')\n",
    "net = DeepLSD(conf)\n",
    "net.load_state_dict(ckpt['model'])\n",
    "net = net.to(device).eval()\n",
    "\n",
    "img_names = os.listdir(r\"D:\\3d-reconstruction\\DeepLSD\\room-downsam\") #[0:1]\n",
    "print(img_names)\n",
    "\n",
    "for name in img_names:\n",
    "    print(name)\n",
    "\n",
    "    img_path = os.path.join(r\"D:\\3d-reconstruction\\DeepLSD\\room-downsam\", name)\n",
    "\n",
    "    # Load an image\n",
    "    img = cv2.imread(img_path)[:, :, ::-1]\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Detect (and optionally refine) the lines\n",
    "    inputs = {'image': torch.tensor(gray_img, dtype=torch.float, device=device)[None, None] / 255.}\n",
    "    with torch.no_grad():\n",
    "        out = net(inputs)\n",
    "        pred_lines = out['lines'][0]\n",
    "\n",
    "    print(pred_lines.shape)\n",
    "    print(pred_lines[0])\n",
    "\n",
    "    # # Plot the predictions\n",
    "    # plot_images([img], ['All lines'], cmaps='gray')\n",
    "    # plot_lines([pred_lines], indices=range(1))\n",
    "\n",
    "    # Shorten the lines\n",
    "    shortened = shorten_lines(pred_lines, shrink_factor=0.2)\n",
    "    # plot_images([img], ['Shortened lines'], cmaps='gray')\n",
    "    # plot_lines([shortened], indices=range(1))\n",
    "\n",
    "    img_name = name.split(\".\")[0]\n",
    "    print(img_name)\n",
    "    mask_names = [name for name in os.listdir(rf\"D:\\3d-reconstruction\\DeepLSD\\masks\\{img_name}_mask\") if \".json\" not in name]\n",
    "\n",
    "    for mask_name in mask_names:\n",
    "\n",
    "        mask_path = rf\"D:\\3d-reconstruction\\DeepLSD\\masks\\{img_name}_mask\\{mask_name}\"\n",
    "        inside_both, inside_one = check_lines_in_mask(mask_path, shortened)\n",
    "\n",
    "        print(\"inside_both shape:\", inside_both.shape)  # Expected: (N,2,2)\n",
    "        print(\"inside_one shape:\", inside_one.shape)    # Expected: (M,2,2)\n",
    "\n",
    "        plot_images([img], ['Lines within Mask'], cmaps='gray')\n",
    "        plot_lines([inside_both], indices=range(1))\n",
    "\n",
    "        if inside_both.size != 0:\n",
    "\n",
    "\n",
    "            import numpy as np\n",
    "            from sklearn.cluster import DBSCAN\n",
    "\n",
    "            directions = inside_both[:, 1, :] - inside_both[:, 0, :]  # Compute direction vectors\n",
    "            norms = np.linalg.norm(directions, axis=1, keepdims=True)  # Compute norms\n",
    "            directions_normalized = directions / norms  # Normalize direction vectors\n",
    "\n",
    "            # Step 2: Compute pairwise angle differences in degrees\n",
    "            dot_products = np.dot(directions_normalized, directions_normalized.T)  # Cosine similarity matrix\n",
    "            dot_products = np.clip(dot_products, -1, 1)  # Ensure values stay within valid range\n",
    "            angles = np.degrees(np.arccos(np.abs(dot_products)))  # Convert to absolute angle differences\n",
    "\n",
    "            # Step 3: Use DBSCAN with an angle threshold\n",
    "            angle_threshold = 5  # Maximum difference in degrees for parallel lines\n",
    "            clustering = DBSCAN(eps=angle_threshold, min_samples=1, metric=\"precomputed\").fit(angles)\n",
    "\n",
    "            # Step 4: Group lines by clusters\n",
    "            groups = {}\n",
    "            group_lengths = {}\n",
    "\n",
    "            for idx, label in enumerate(clustering.labels_):\n",
    "                if label not in groups:\n",
    "                    groups[label] = []\n",
    "                    group_lengths[label] = 0  # Initialize total length for the group\n",
    "\n",
    "                groups[label].append(inside_both[idx])\n",
    "                \n",
    "                # Compute and accumulate total length of the lines in the group\n",
    "                line_length = np.linalg.norm(inside_both[idx, 1] - inside_both[idx, 0])  # Euclidean distance\n",
    "                group_lengths[label] += line_length\n",
    "\n",
    "            # Step 5: Select the best group based on the number of lines and total length\n",
    "            best_group_label = max(groups.keys(), key=lambda lbl: (group_lengths[lbl], len(groups[lbl])))\n",
    "\n",
    "            best_group = groups[best_group_label]\n",
    "            best_group_length = group_lengths[best_group_label]\n",
    "\n",
    "            # Compute distances for all lines in the best group\n",
    "            line_distances = [np.linalg.norm(line[1] - line[0]) for line in best_group]\n",
    "\n",
    "            # Find the index of the longest line\n",
    "            longest_line_index = np.argmax(line_distances)\n",
    "\n",
    "            # Get the longest line\n",
    "            longest_line = best_group[longest_line_index]\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Best Group: {best_group_label}\")\n",
    "            longest_line = np.array(longest_line).reshape(1,2,2)\n",
    "            plot_images([img], ['Lines within Mask'], cmaps='gray')\n",
    "            plot_lines([longest_line], indices=range(1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # break\n",
    "\n",
    "            # # Compute lengths and find the longest line\n",
    "            # lengths = np.array([compute_length(line) for line in inside_both])\n",
    "\n",
    "            # longest_index = np.argmax(lengths)\n",
    "            # longest_line = inside_both[longest_index].reshape(1,2,2)\n",
    "\n",
    "            # print(longest_line.shape)\n",
    "\n",
    "            # plot_images([img], ['Longest line within Mask'], cmaps='gray')\n",
    "            # plot_lines([longest_line], indices=range(1))\n",
    "\n",
    "            # print(longest_line)\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hawp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
